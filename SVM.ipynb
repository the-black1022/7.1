{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score,precision_score,recall_score\n",
    "\n",
    "import tqdm\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\新建文件夹\\数据\\1.csv\",index_col='Date') \n",
    "index = data.index\n",
    "\n",
    "X = data.loc[:,'volume':'cci'].to_numpy()\n",
    "y = data['label1'].values\n",
    "\n",
    "#将时间序列划分为5份\n",
    "tscv_train = TimeSeriesSplit(5)\n",
    "cv_index_global = list(tscv_train.split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****model, cv iteration:0*****\n",
      "0.5370370370370371\n",
      "0.5369021812762498\n",
      "0.5526838966202784\n",
      "*****model, cv iteration:1*****\n",
      "0.4897119341563786\n",
      "0.48991935483870963\n",
      "0.4897119341563786\n",
      "*****model, cv iteration:2*****\n",
      "0.565843621399177\n",
      "0.5\n",
      "0.7227332457293035\n",
      "*****model, cv iteration:3*****\n",
      "0.5781893004115226\n",
      "0.5\n",
      "0.7327249022164276\n",
      "*****model, cv iteration:4*****\n",
      "0.49176954732510286\n",
      "0.5\n",
      "0.6593103448275862\n",
      "\n",
      "\n",
      "{SVM}'s mean value of accuracy is:  0.5325102880658436\n",
      "{SVM}'s mean value of auc is:  0.5053643072229919\n",
      "{SVM}'s mean value of f1 is:  0.6314328647099948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "params_grid={'C':[0.001,0.01,0.1,1,10,100],\"gamma\":np.linspace(0.001,1,10)}\n",
    "acc,auc,f1=[],[],[]\n",
    "for i in range(len(cv_index_global)): \n",
    "    \n",
    "    print(f'*****model, cv iteration:{i}*****')\n",
    "    #spliting the training and testing set in cv iteration\n",
    "    X_train=X[cv_index_global[i][0]]\n",
    "    y_train=y[cv_index_global[i][0]]\n",
    "\n",
    "    X_test=X[cv_index_global[i][1]]\n",
    "    y_test=y[cv_index_global[i][1]]\n",
    "\n",
    "    #scale the training set and testing set(based on the sclaer from training set)\n",
    "    scaler=MinMaxScaler().fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    svmclf=GridSearchCV(SVC(random_state=123,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "    \n",
    "    y_predict = svmclf.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test,y_predict))\n",
    "    auc.append(roc_auc_score(y_test,y_predict))\n",
    "    f1.append(f1_score(y_test,y_predict))\n",
    "#    print(\"best param\" + str(svmclf.best_params_))\n",
    "    print(accuracy_score(y_test,y_predict))\n",
    "    print(roc_auc_score(y_test,y_predict))\n",
    "    print(f1_score(y_test,y_predict))\n",
    "print(\"\\n\")\n",
    "print(\"{SVM}'s mean value of accuracy is: \",np.mean(acc))\n",
    "print(\"{SVM}'s mean value of auc is: \",np.mean(auc))\n",
    "print(\"{SVM}'s mean value of f1 is: \",np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid={'C':[0.001,0.01,0.1,1,10,100],\"gamma\":np.linspace(0.001,1,10)}\n",
    "# =============================================================000==================\n",
    "X_train=X[cv_index_global[0][0]]\n",
    "y_train=y[cv_index_global[0][0]]\n",
    "\n",
    "X_test=X[cv_index_global[0][1]]\n",
    "y_test=y[cv_index_global[0][1]]\n",
    "\n",
    "#scale the training set and testing set(based on the sclaer from training set)\n",
    "scaler=MinMaxScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svmclf=GridSearchCV(SVC(random_state=666,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "\n",
    "a = svmclf.predict(X_test)\n",
    "\n",
    "# =============================================================111==================\n",
    "X_train=X[cv_index_global[1][0]]\n",
    "y_train=y[cv_index_global[1][0]]\n",
    "\n",
    "X_test=X[cv_index_global[1][1]]\n",
    "y_test=y[cv_index_global[1][1]]\n",
    "\n",
    "#scale the training set and testing set(based on the sclaer from training set)\n",
    "scaler=MinMaxScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svmclf=GridSearchCV(SVC(random_state=666,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "\n",
    "b = svmclf.predict(X_test)\n",
    "\n",
    "# =============================================================222==================\n",
    "X_train=X[cv_index_global[2][0]]\n",
    "y_train=y[cv_index_global[2][0]]\n",
    "\n",
    "X_test=X[cv_index_global[2][1]]\n",
    "y_test=y[cv_index_global[2][1]]\n",
    "\n",
    "#scale the training set and testing set(based on the sclaer from training set)\n",
    "scaler=MinMaxScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svmclf=GridSearchCV(SVC(random_state=666,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "\n",
    "c = svmclf.predict(X_test)\n",
    "\n",
    "# =============================================================333==================\n",
    "X_train=X[cv_index_global[3][0]]\n",
    "y_train=y[cv_index_global[3][0]]\n",
    "\n",
    "X_test=X[cv_index_global[3][1]]\n",
    "y_test=y[cv_index_global[3][1]]\n",
    "\n",
    "#scale the training set and testing set(based on the sclaer from training set)\n",
    "scaler=MinMaxScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svmclf=GridSearchCV(SVC(random_state=666,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "\n",
    "d = svmclf.predict(X_test)\n",
    "\n",
    "# =============================================================444==================\n",
    "X_train=X[cv_index_global[4][0]]\n",
    "y_train=y[cv_index_global[4][0]]\n",
    "\n",
    "X_test=X[cv_index_global[4][1]]\n",
    "y_test=y[cv_index_global[4][1]]\n",
    "\n",
    "#scale the training set and testing set(based on the sclaer from training set)\n",
    "scaler=MinMaxScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svmclf=GridSearchCV(SVC(random_state=666,probability=True,kernel='rbf'),params_grid,scoring='f1',\n",
    "                    n_jobs=-1,cv=tscv_train,refit=True).fit(X_train,y_train)\n",
    "\n",
    "e = svmclf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 259, -1.0: 227})\n",
      "Counter({1.0: 248, -1.0: 238})\n",
      "Counter({1.0: 486})\n",
      "Counter({1.0: 486})\n",
      "Counter({1.0: 486})\n"
     ]
    }
   ],
   "source": [
    "#y_predict的分类情况\n",
    "from collections import Counter\n",
    "print(Counter(a))\n",
    "print(Counter(b))\n",
    "print(Counter(c))\n",
    "print(Counter(d))\n",
    "print(Counter(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 254, -1.0: 233})\n",
      "Counter({1.0: 498, -1.0: 475})\n",
      "Counter({1.0: 736, -1.0: 723})\n",
      "Counter({1.0: 1011, -1.0: 934})\n",
      "Counter({1.0: 1292, -1.0: 1139})\n"
     ]
    }
   ],
   "source": [
    "##y_test的分类情况\n",
    "print(Counter(y[cv_index_global[0][0]]))\n",
    "print(Counter(y[cv_index_global[1][0]]))\n",
    "print(Counter(y[cv_index_global[2][0]]))\n",
    "print(Counter(y[cv_index_global[3][0]]))\n",
    "print(Counter(y[cv_index_global[4][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
